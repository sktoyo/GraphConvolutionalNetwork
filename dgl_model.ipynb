{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgl_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rkWhmWu71nNn",
        "kKIUyLVJMy91",
        "BwA4uHZsZ75g"
      ],
      "toc_visible": true,
      "mount_file_id": "1xFyigYAKCVh1pTHGKAMJwWvIjJaPWPiw",
      "authorship_tag": "ABX9TyOg7zEFLY9qKy1enGCmActN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44b1ed239a3f40dcb4c20cdf8a9311c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b8cda218e064deea7ef9fa01af76dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_062e8805cf654fb09d05ce4a586ac82b",
              "IPY_MODEL_68504157f09e4f79812615a849e0b168"
            ]
          }
        },
        "7b8cda218e064deea7ef9fa01af76dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "062e8805cf654fb09d05ce4a586ac82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc529bf3a5ca46769ce69dcecda2955f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43ab8e888cbc47dab6e85bf813cff5c7"
          }
        },
        "68504157f09e4f79812615a849e0b168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edcca4ecfff442a2a78a26cae6db8ebb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 78498/? [00:30&lt;00:00, 2614.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0715290ce90400296b47c141177de07"
          }
        },
        "bc529bf3a5ca46769ce69dcecda2955f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43ab8e888cbc47dab6e85bf813cff5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edcca4ecfff442a2a78a26cae6db8ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0715290ce90400296b47c141177de07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7905c8f329d14376ae1966da12376a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdd16987c28841b1a87cd71acbd0933b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad5d2a158d4a4a8da2d06b997d075519",
              "IPY_MODEL_7f914190608b4ecaac17cc3f70624536"
            ]
          }
        },
        "cdd16987c28841b1a87cd71acbd0933b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad5d2a158d4a4a8da2d06b997d075519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fb5c41ef22b43829f0eaa60757c9138",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_233975c9b3e84365903f319f51244d84"
          }
        },
        "7f914190608b4ecaac17cc3f70624536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77ef1ccb27c14030b066c05667ad775a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/500 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63714c4164f84c489b46e14a0da24bb1"
          }
        },
        "5fb5c41ef22b43829f0eaa60757c9138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "233975c9b3e84365903f319f51244d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77ef1ccb27c14030b066c05667ad775a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63714c4164f84c489b46e14a0da24bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sktoyo/GraphConvolutionalNetwork/blob/main/dgl_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKgsplR9ZOz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44915ac-3fc2-441c-fd89-f5f51ae2d41c"
      },
      "source": [
        "# in colab environment\n",
        "!pip install dgl-cu101\n",
        "!python -m dgl.backend.set_default_backend tensorflow\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Research/disease gene prediction/python project/src')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dgl-cu101 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2020.12.5)\n",
            "2021-03-06 09:49:44.170739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Using backend: tensorflow\n",
            "2021-03-06 09:49:48.483025: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-06 09:49:48.498909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-06 09:49:48.552764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:48.553460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-03-06 09:49:48.553520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-03-06 09:49:48.609759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-03-06 09:49:48.609863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-03-06 09:49:48.742334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-06 09:49:48.793560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-06 09:49:49.027421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-06 09:49:49.092235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-03-06 09:49:49.095755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-03-06 09:49:49.095916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:49.096601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:49.099904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-03-06 09:49:49.104735: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-06 09:49:49.104882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:49.105486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-03-06 09:49:49.105541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-03-06 09:49:49.105593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-03-06 09:49:49.105615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-03-06 09:49:49.105637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-06 09:49:49.105657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-06 09:49:49.105677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-06 09:49:49.105696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-03-06 09:49:49.105716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-03-06 09:49:49.105790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:49.106382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:49.106943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-03-06 09:49:49.109445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-03-06 09:49:53.519039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-06 09:49:53.519090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-03-06 09:49:53.519103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-03-06 09:49:53.591187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:53.591892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:53.592476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-06 09:49:53.593075: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-06 09:49:53.593132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'dgl.backend.set_default_backend' found in sys.modules after import of package 'dgl.backend', but prior to execution of 'dgl.backend.set_default_backend'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Setting the default backend to \"tensorflow\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkWhmWu71nNn"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB91b-RUbAYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1267c6c5-bfc6-4bb3-d573-ce63f1b17ee4"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import dgl\n",
        "import random\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import dgl.function as fn\n",
        "from dgl.nn.tensorflow import edge_softmax, GATConv\n",
        "from dgl.nn.tensorflow import GraphConv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using backend: tensorflow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKIUyLVJMy91"
      },
      "source": [
        "## Resource paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwIwQ3p2_4-y"
      },
      "source": [
        "resource_path = '../../../Resources/'\n",
        "Humannet_path = resource_path + 'humannet/'\n",
        "oncoKB_path = resource_path + 'OncoKB/'\n",
        "cosmic_path = resource_path + 'CGC cosmic/'\n",
        "ncbi_path = resource_path + 'ncbi gene info/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2FOD9xoO9sB"
      },
      "source": [
        "expression_path = '../data/expression_data/TCGA-BRCA/'\n",
        "mutation_path = '../data/mutation data/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbrDx2e3sb5X"
      },
      "source": [
        "preprocess_dir = 'preprocessing/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyX5uGtwHBac"
      },
      "source": [
        "# Experiment Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMOY7M4dHEsF"
      },
      "source": [
        "expression_data = pd.read_csv(expression_path + 'TCGA_BRCA_TPM_symbol.tsv', sep='\\t', index_col=0)\n",
        "mutation_data = pd.read_csv(mutation_path + 'TCGA_BRCA_mutation_feature.txt', sep='\\t', index_col=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B14UaYNZHvBx"
      },
      "source": [
        "mutation_data = mutation_data.drop(columns=['gene length'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft0ZF5waIPCD"
      },
      "source": [
        "input_data = pd.merge(expression_data, mutation_data, left_index=True, right_index=True).drop_duplicates()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VufYlQVDvjSU"
      },
      "source": [
        "experiment_gene_list = input_data.index.to_list()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM6bno9nMudS"
      },
      "source": [
        "##Create Network from Humannet DB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWCbpwZG5Jg"
      },
      "source": [
        "gene_id_info = pd.read_csv(ncbi_path + 'Homo_sapiens.gene_info.txt', sep='\\t')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ_zribyHYcG"
      },
      "source": [
        "gene_id_info = gene_id_info.drop(columns=['#tax_id'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykfdZS7BHmj4"
      },
      "source": [
        "gene_id_info = gene_id_info[['GeneID', 'Symbol']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48FqC10SHyja"
      },
      "source": [
        "entrez_id = gene_id_info['GeneID'].tolist()\n",
        "entrez_symbol = gene_id_info['Symbol'].tolist()\n",
        "entrez_id_dict = dict()\n",
        "\n",
        "for i, id in enumerate(entrez_id):\n",
        "  entrez_id_dict[str(id)] = entrez_symbol[i]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1L9ov5CMdJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "44b1ed239a3f40dcb4c20cdf8a9311c9",
            "7b8cda218e064deea7ef9fa01af76dd6",
            "062e8805cf654fb09d05ce4a586ac82b",
            "68504157f09e4f79812615a849e0b168",
            "bc529bf3a5ca46769ce69dcecda2955f",
            "43ab8e888cbc47dab6e85bf813cff5c7",
            "edcca4ecfff442a2a78a26cae6db8ebb",
            "e0715290ce90400296b47c141177de07"
          ]
        },
        "outputId": "2cf27dee-f9f4-4511-eac0-e2ce66e38d3e"
      },
      "source": [
        "humannet_DF = pd.read_csv(Humannet_path + 'HumanNet-XN.tsv', sep='\\t')\n",
        "humannet_DF = humannet_DF.astype('str')\n",
        "\n",
        "# preprocessing of changed entrezIDs\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID1 != '10896']\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID2 != '10896']\n",
        "\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID1 != '285464']\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID2 != '285464']\n",
        "\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID1 != '729574']\n",
        "humannet_DF = humannet_DF[humannet_DF.EntrezGeneID2 != '729574']\n",
        "\n",
        "humannet_genes = list(set(humannet_DF['EntrezGeneID1'].to_list() + humannet_DF['EntrezGeneID2'].to_list()))\n",
        "humannet_genes = [geneid for geneid in humannet_genes if geneid in entrez_id_dict]\n",
        "\n",
        "humannet_edges = list()\n",
        "humannet_edges_feature = list()\n",
        "\n",
        "# total size is \n",
        "for index, row in tqdm(humannet_DF.iterrows()):\n",
        "  gene1 = entrez_id_dict[row['EntrezGeneID1']]\n",
        "  gene2 = entrez_id_dict[row['EntrezGeneID2']]\n",
        "  if gene1 in experiment_gene_list and gene2 in experiment_gene_list:\n",
        "    humannet_edges.append([gene1, gene2])\n",
        "    humannet_edges_feature.append(row['LLS'])\n",
        "\n",
        "# remove self loop, remove duplicated reverse edges, make bidirectionality\n",
        "humannet_edges = list(humannet_edges for humannet_edges,_ in itertools.groupby(humannet_edges))\n",
        "humannet_edges = [edge for edge in humannet_edges if edge[0] != edge[1]]\n",
        "humannet_edges_reverse = [[edge[1], edge[0]] for edge in humannet_edges]\n",
        "humannet_edges = humannet_edges + humannet_edges_reverse\n",
        "humannet_edges = list(set(map(tuple,humannet_edges)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44b1ed239a3f40dcb4c20cdf8a9311c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNeB6MvCskEF"
      },
      "source": [
        "## Join gene list btw network and exp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQXfa3sJsr7J"
      },
      "source": [
        "humannet_genes = set([edge[0] for edge in humannet_edges])\r\n",
        "input_data = input_data[input_data.index.isin(list(humannet_genes))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjOwg0Kry9m"
      },
      "source": [
        "input_data = input_data.sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUc503PHsGOK"
      },
      "source": [
        "gene_list = input_data.index.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIqr-pkVsJo6"
      },
      "source": [
        "gene_index_dict = dict()\r\n",
        "with open(preprocess_dir + 'gene_index.tsv', 'w') as f:\r\n",
        "  for i in range(len(gene_list)):\r\n",
        "    gene_info = [str(i), gene_list[i]]\r\n",
        "    gene_index_dict[gene_list[i]] = i\r\n",
        "    f.write('\\t'.join(gene_info) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fU1UlQDdE92"
      },
      "source": [
        "# change symbol to gene index in gene_index_dict\r\n",
        "humannet_edges = [[gene_index_dict[edge[0]], gene_index_dict[edge[1]]] for edge in humannet_edges]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krzpeZ1L5nrP"
      },
      "source": [
        "humannet_edges_node1 = [edge[0] for edge in humannet_edges]\r\n",
        "humannet_edges_node2 = [edge[1] for edge in humannet_edges]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Muy0_MJIVE"
      },
      "source": [
        "input_features = input_data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZIEXX0Px9Cn"
      },
      "source": [
        "## create network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh24g1sqx_IQ"
      },
      "source": [
        "# create network\r\n",
        "humannet_dgl = dgl.graph((humannet_edges_node1, humannet_edges_node2))\r\n",
        "cuda_humannet_dgl = humannet_dgl.to('/gpu:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hivwsSz5sAUx"
      },
      "source": [
        "humannet_adj = sp.csr_matrix((np.ones(len(humannet_edges)), (humannet_edges_node1, humannet_edges_node2)), shape=(len(humannet_edges), len(humannet_edges)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oARVAsdRknjH"
      },
      "source": [
        "# Label creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg2M_sfrmsjB"
      },
      "source": [
        "def convert_sparse_matrix_to_sparse_tensor(inputs):\r\n",
        "    coo = inputs.tocoo()\r\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\r\n",
        "    output = tf.SparseTensor(indices, coo.data.astype('float64'), coo.shape)\r\n",
        "    output = tf.dtypes.cast(output, tf.float32)\r\n",
        "    return output\r\n",
        "\r\n",
        "def sparse_to_tuple(sparse_mx):\r\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\r\n",
        "        sparse_mx = sparse_mx.tocoo()\r\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\r\n",
        "    values = sparse_mx.data\r\n",
        "    shape = sparse_mx.shape\r\n",
        "    return coords, values, shape\r\n",
        "    \r\n",
        "def data_split(adj, validation_rate,\r\n",
        "               test_rate):  # get train set, validation set, test set, using upper triangle of adj matrix, in AutoEncoder\r\n",
        "    coords, values, shape = sparse_to_tuple(adj)\r\n",
        "    test_num = int(len(values) * test_rate)\r\n",
        "    validation_num = int(len(values) * validation_rate)\r\n",
        "\r\n",
        "    # create positive set for train, validation, test from\r\n",
        "    coords = coords.tolist()\r\n",
        "    positive_set = np.array([coo for coo in coords if coo[0] < coo[1]])\r\n",
        "    positive_idx = np.array([coo[0] * shape[0] + coo[1] for coo in positive_set])\r\n",
        "\r\n",
        "    np.random.shuffle(positive_set)\r\n",
        "\r\n",
        "    test_pos = positive_set[:test_num]\r\n",
        "    valid_pos = positive_set[test_num:(test_num + validation_num)]\r\n",
        "    train_edges = positive_set[(test_num + validation_num):]\r\n",
        "\r\n",
        "    # create negative set for validation, test\r\n",
        "    negative_idx_list = list()\r\n",
        "\r\n",
        "\r\n",
        "    while len(negative_idx_list) < test_num + validation_num:\r\n",
        "        i = random.randrange(shape[0])\r\n",
        "        j = random.randrange(shape[0])\r\n",
        "        if i < j:\r\n",
        "            idx = i * shape[0] + j\r\n",
        "            if idx not in positive_idx:\r\n",
        "                negative_idx_list.append(idx)\r\n",
        "\r\n",
        "    negative_idx = np.array(negative_idx_list)\r\n",
        "\r\n",
        "    np.random.shuffle(negative_idx)\r\n",
        "    test_neg = np.array([[idx // shape[0], idx % shape[0]] for idx in negative_idx[:test_num]])\r\n",
        "    valid_neg = np.array(\r\n",
        "        [[idx // shape[0], idx % shape[0]] for idx in negative_idx[test_num:(test_num + validation_num)]])\r\n",
        "\r\n",
        "    data = np.ones(len(train_edges))\r\n",
        "\r\n",
        "    # reconstruct train adjacency matrix\r\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\r\n",
        "    adj_train = adj_train + adj_train.T\r\n",
        "\r\n",
        "    return adj_train, train_edges, valid_pos, valid_neg, test_pos, test_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZBcpI5cI6NJ"
      },
      "source": [
        "# oncoKB parsing (label creation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA3a3hzpLOFn"
      },
      "source": [
        "onogene_TSG_pd = pd.read_csv(oncoKB_path + '/cancerGeneList.tsv', sep = '\\t').astype('str')\n",
        "cancer_gene_pd = pd.read_csv(oncoKB_path + '/oncokb_biomarker_drug_associations.tsv', sep = '\\t').astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "AN-xyu-B3OgE",
        "outputId": "5188b737-43e3-49dc-dae2-ec7844f00f6d"
      },
      "source": [
        "onogene_TSG_pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hugo Symbol</th>\n",
              "      <th>Entrez Gene ID</th>\n",
              "      <th>Isoform</th>\n",
              "      <th>RefSeq</th>\n",
              "      <th># of occurrence within resources (Column D-J)</th>\n",
              "      <th>OncoKB Annotated</th>\n",
              "      <th>Is Oncogene</th>\n",
              "      <th>Is Tumor Suppressor Gene</th>\n",
              "      <th>MSK-IMPACT</th>\n",
              "      <th>MSK-HEME</th>\n",
              "      <th>FOUNDATION ONE</th>\n",
              "      <th>FOUNDATION ONE HEME</th>\n",
              "      <th>Vogelstein</th>\n",
              "      <th>SANGER CGC(05/30/2017)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LYL1</td>\n",
              "      <td>4066</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LYN</td>\n",
              "      <td>4067</td>\n",
              "      <td>ENST00000519728</td>\n",
              "      <td>NM_002350.3</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SH2D1A</td>\n",
              "      <td>4068</td>\n",
              "      <td>ENST00000371139</td>\n",
              "      <td>NM_002351.4</td>\n",
              "      <td>3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OLIG2</td>\n",
              "      <td>10215</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EPCAM</td>\n",
              "      <td>4072</td>\n",
              "      <td>ENST00000263735</td>\n",
              "      <td>NM_002354.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>GREM1</td>\n",
              "      <td>26585</td>\n",
              "      <td>ENST00000300177</td>\n",
              "      <td>NM_013372.6</td>\n",
              "      <td>3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>EGFL7</td>\n",
              "      <td>51162</td>\n",
              "      <td>ENST00000308874</td>\n",
              "      <td>NM_201446.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>LTK</td>\n",
              "      <td>4058</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>SPRTN</td>\n",
              "      <td>83932</td>\n",
              "      <td>ENST00000295050</td>\n",
              "      <td>NM_032018.6</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>STK40</td>\n",
              "      <td>83931</td>\n",
              "      <td>ENST00000373129</td>\n",
              "      <td>NM_032017.1</td>\n",
              "      <td>3</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1059 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Hugo Symbol Entrez Gene ID  ... Vogelstein SANGER CGC(05/30/2017)\n",
              "0           LYL1           4066  ...         No                    Yes\n",
              "1            LYN           4067  ...         No                     No\n",
              "2         SH2D1A           4068  ...         No                     No\n",
              "3          OLIG2          10215  ...         No                    Yes\n",
              "4          EPCAM           4072  ...         No                     No\n",
              "...          ...            ...  ...        ...                    ...\n",
              "1054       GREM1          26585  ...         No                     No\n",
              "1055       EGFL7          51162  ...         No                     No\n",
              "1056         LTK           4058  ...         No                     No\n",
              "1057       SPRTN          83932  ...         No                     No\n",
              "1058       STK40          83931  ...         No                     No\n",
              "\n",
              "[1059 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR1P2trAOfT4"
      },
      "source": [
        "# all oncoKB genes\n",
        "oncoKB_gene_dict = dict()\n",
        "for index, row in onogene_TSG_pd.iterrows():\n",
        "  gene_id = row['Entrez Gene ID']\n",
        "  gene_symbol = row['Hugo Symbol']\n",
        "  oncogene = row['Is Oncogene']\n",
        "  TSG = row['Is Tumor Suppressor Gene']\n",
        "  disease_rows = cancer_gene_pd.loc[cancer_gene_pd['Gene'] == gene_symbol]\n",
        "  diseases = list(set(disease_rows['Tumor Type'].to_list()))\n",
        "  oncoKB_gene_dict[gene_symbol] = {'oncogene': oncogene, 'TSG': TSG, 'diseases':diseases}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Vwm1J_4Zf2"
      },
      "source": [
        "# breast oncoKB genes\r\n",
        "oncoKB_gene_dict = dict()\r\n",
        "for index, row in onogene_TSG_pd.iterrows():\r\n",
        "  gene_id = row['Entrez Gene ID']\r\n",
        "  gene_symbol = row['Hugo Symbol']\r\n",
        "  oncogene = row['Is Oncogene']\r\n",
        "  TSG = row['Is Tumor Suppressor Gene']\r\n",
        "  disease_rows = cancer_gene_pd.loc[cancer_gene_pd['Gene'] == gene_symbol]\r\n",
        "  diseases = list(set(disease_rows['Tumor Type'].to_list()))\r\n",
        "  oncoKB_gene_dict[gene_symbol] = {'oncogene': oncogene, 'TSG': TSG, 'diseases':diseases}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjJMOc9QueIl"
      },
      "source": [
        "unknown_label = list()\n",
        "oncogene_label = list()\n",
        "TSG_label = list()\n",
        "network_node_list = list(gene_list)\n",
        "for gene_symbol in gene_list:\n",
        "  if not gene_symbol in list(oncoKB_gene_dict.keys()):\n",
        "    unknown_label.append(1)\n",
        "    oncogene_label.append(0)\n",
        "    TSG_label.append(0)\n",
        "  else:\n",
        "    gene_info = oncoKB_gene_dict[gene_symbol]\n",
        "    if gene_info['oncogene'] == 'Yes' and gene_info['TSG'] == 'Yes':\n",
        "      unknown_label.append(1)\n",
        "      oncogene_label.append(0)\n",
        "      TSG_label.append(0)\n",
        "    elif gene_info['oncogene'] == 'Yes':\n",
        "      unknown_label.append(0)\n",
        "      oncogene_label.append(1)\n",
        "      TSG_label.append(0)\n",
        "    elif gene_info['TSG'] == 'Yes':\n",
        "      unknown_label.append(0)\n",
        "      oncogene_label.append(0)\n",
        "      TSG_label.append(1)\n",
        "    else:\n",
        "      unknown_label.append(1)\n",
        "      oncogene_label.append(0)\n",
        "      TSG_label.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8ALKk65w7dO"
      },
      "source": [
        "label_df = pd.DataFrame({'unknown': unknown_label, 'oncogene': oncogene_label, 'TSG': TSG_label}, index=network_node_list)\r\n",
        "label_array = label_df.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aVfsRIszGTN"
      },
      "source": [
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "def data_split(label_array, column_idx, valid_ratio, test_ratio):\n",
        "  # Index of Known labels\n",
        "  idx_list = [i for i in range(len(label_array))]\n",
        "  y_idx = np.array([i for i in idx_list if label_array[i][column_idx] == 1])\n",
        "\n",
        "  # Random split\n",
        "  train_idx, test_idx= train_test_split(y_idx, test_size=test_ratio, random_state=42)\n",
        "  train_idx, valid_idx= train_test_split(train_idx, test_size=(valid_ratio)/(1-test_ratio), random_state=42)\n",
        "\n",
        "  # Mask\n",
        "  train_mask = sample_mask(train_idx, label_array.shape[0])\n",
        "  valid_mask = sample_mask(valid_idx, label_array.shape[0])\n",
        "  test_mask = sample_mask(test_idx, label_array.shape[0])\n",
        "  \n",
        "  return train_mask, valid_mask, test_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uDTja6QpuLY"
      },
      "source": [
        "# creation of negative dataset\r\n",
        "label_list = list()\r\n",
        "for label in label_array:\r\n",
        "  if label[1] == 1 or label[2] == 1:\r\n",
        "    label_list.append([1, 0])\r\n",
        "  else:\r\n",
        "    label_list.append([0, 0])\r\n",
        "\r\n",
        "idx_list = [i for i in range(len(label_list))]\r\n",
        "neg_idx = np.array([i for i in idx_list if label_list[i][0] == 0])\r\n",
        "pos_count = len([i for i in idx_list if label_list[i][0] == 1])\r\n",
        "\r\n",
        "neg_dataset = list()\r\n",
        "for i in range(10):\r\n",
        "  random.shuffle(neg_idx)\r\n",
        "  neg_dataset.append(neg_idx[:2*pos_count])\r\n",
        "  neg_idx = neg_idx[2*pos_count:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vbl2SgL7LU8"
      },
      "source": [
        "\n",
        "\n",
        "# Data sets\n",
        "for i in range(len(label_array)):\n",
        "  if not i in neg_dataset[0]:\n",
        "    label_array[i][0] = 0\n",
        "\n",
        "# oncogene data\n",
        "train_oncogene_mask, valid_oncogene_mask, test_oncogene_mask = data_split(label_array, 1, 0.15, 0.15)\n",
        "\n",
        "# TSG data\n",
        "train_tsg_mask, valid_tsg_mask, test_tsg_mask = data_split(label_array, 2, 0.15, 0.15)\n",
        "\n",
        "# Negative data (Random)\n",
        "train_neg_mask, valid_neg_mask, test_neg_mask = data_split(label_array, 0, 0.15, 0.15)\n",
        "\n",
        "# train, validation, test\n",
        "train_mask = np.logical_or.reduce((train_oncogene_mask, train_tsg_mask, train_neg_mask))\n",
        "val_mask = np.logical_or.reduce((valid_oncogene_mask, valid_tsg_mask, valid_neg_mask))\n",
        "test_mask = np.logical_or.reduce((test_oncogene_mask, test_tsg_mask, test_neg_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q1BLDZLurhe",
        "outputId": "335a70ec-85e1-4f84-9065-47aeef846776"
      },
      "source": [
        "cuda_humannet_dgl.adjacency_matrix."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DGLHeteroGraph.adjacency_matrix of Graph(num_nodes=13195, num_edges=676436,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaLDg-Ia9ufM",
        "outputId": "3934f9a4-6109-434d-ea21-bd56a8e9ad8b"
      },
      "source": [
        "humannet_adj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<13195x13195 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 676436 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r67XQ2ri97RW",
        "outputId": "9d28bb69-1509-4320-bce6-f0e2811675d3"
      },
      "source": [
        "label_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LcF0Hul9Vsv"
      },
      "source": [
        "label_array = label_array.tolist()\r\n",
        "for i in range(len(label_array)):\r\n",
        "  if label_array[i][1] == 1 or label_array[i][2] == 1:\r\n",
        "    label_array[i] = np.array([1, 0])\r\n",
        "  elif label_array[i][0] == 1:\r\n",
        "    label_array[i] = np.array([0, 1])\r\n",
        "  else:\r\n",
        "    label_array[i] = np.array([0, 0])\r\n",
        "label_array = np.array(label_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiE5vzhu9_kT",
        "outputId": "cbd76b17-5672-4900-ccda-ee6c66204b38"
      },
      "source": [
        "label_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       ...,\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwA4uHZsZ75g"
      },
      "source": [
        "#COSMIC parsing (label creation2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ojrODnaCZP"
      },
      "source": [
        "census_df = pd.read_csv(cosmic_path + 'Census_allThu Dec 10 06_53_08 2020.tsv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg7ARJbZAVdt"
      },
      "source": [
        "cancer_list = list()\r\n",
        "for raw in census_df['Tumour Types(Somatic)'].to_list():\r\n",
        "  if type(raw) == str:\r\n",
        "    cancer_list += raw.split(', ')\r\n",
        "for raw in census_df['Tumour Types(Germline)'].to_list():\r\n",
        "  if type(raw) == str:\r\n",
        "    cancer_list += raw.split(', ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0wTXapBiQf"
      },
      "source": [
        "cancer_list = list(set(cancer_list))\r\n",
        "cancer_list = list(map(str.strip, cancer_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQSXBDnyCjA6"
      },
      "source": [
        "cancer_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JncPc0R5CrTw"
      },
      "source": [
        "for i in cancer_list:\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_zljV-teNqG"
      },
      "source": [
        "larger_class = ['others', 'other tumour types', 'carcinoma']\n",
        "\n",
        "somatic_index1 = census_df['Tumour Types(Somatic)'].str.contains('breast').fillna(False)\n",
        "somatic_index2 = census_df['Tumour Types(Somatic)'].isin(larger_class)\n",
        "germline_index1 = census_df['Tumour Types(Germline)'].str.contains('breast').fillna(False)\n",
        "germline_index2 = census_df['Tumour Types(Germline)'].isin(larger_class)\n",
        "# (census_df['Tumour Types(Somatic)'].str.contains('breast') | census_df['Tumour Types(Germline)'].str.contains('breast'))[:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8tIJt7n04i_",
        "outputId": "79ef3c0a-22d7-4208-e37a-f3e5d0a04086"
      },
      "source": [
        "census_df['Tumour Types(Somatic)'] == 'others'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "718    False\n",
              "719    False\n",
              "720    False\n",
              "721    False\n",
              "722    False\n",
              "Name: Tumour Types(Somatic), Length: 723, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7eLRywlcZIW"
      },
      "source": [
        "breast_df = census_df.loc[somatic_index1|somatic_index2|germline_index1|germline_index2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZptoD3WiJ_z"
      },
      "source": [
        "breast_cdg = breast_df['Gene Symbol'].tolist()\n",
        "breast_cdg = [gene for gene in breast_cdg if gene in input_data.index.to_list()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asHPQln5AOzo",
        "outputId": "2a3d9c92-d7d1-4b99-95fa-f3a77b7bea31"
      },
      "source": [
        "len(breast_cdg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSf7bA-lugtV"
      },
      "source": [
        "label_array = list()\n",
        "for gene in gene_list:\n",
        "  if gene in breast_cdg:\n",
        "    label_array.append([1,0])\n",
        "  else:\n",
        "    label_array.append([0,1])\n",
        "\n",
        "label_array = np.array(label_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV2x0OD1Glg8"
      },
      "source": [
        "idx_list = [i for i in range(len(label_array))]\r\n",
        "neg_idx = np.array([i for i in idx_list if label_array[i][0] == 0])\r\n",
        "pos_count = len([i for i in idx_list if label_array[i][0] == 1])\r\n",
        "\r\n",
        "neg_dataset = list()\r\n",
        "for i in range(10):\r\n",
        "  random.shuffle(neg_idx)\r\n",
        "  neg_dataset.append(neg_idx[:2*pos_count])\r\n",
        "  neg_idx = neg_idx[2*pos_count:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTTcVhEUG3RN"
      },
      "source": [
        "for i in range(len(label_array)):\r\n",
        "  if not i in neg_dataset[0]:\r\n",
        "    label_array[i][1] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0kTScWXw1xe"
      },
      "source": [
        "# label_array = np.reshape(label_array, [len(label_array), 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3fs2do9UcQN",
        "outputId": "0496cb38-990e-49f4-f860-db9c4227800e"
      },
      "source": [
        "label_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13195, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANTqPOtqvKut"
      },
      "source": [
        "train_mask, val_mask, test_mask = data_split(label_array, 0, 0.15, 0.15)\r\n",
        "\r\n",
        "# Negative data (Random)\r\n",
        "train_neg_mask, valid_neg_mask, test_neg_mask = data_split(label_array, 1, 0.15, 0.15)\r\n",
        "\r\n",
        "# Total\r\n",
        "# train, validation, test\r\n",
        "train_mask = np.logical_or.reduce((train_mask, train_neg_mask))\r\n",
        "val_mask = np.logical_or.reduce((val_mask, valid_neg_mask))\r\n",
        "test_mask = np.logical_or.reduce((test_mask, test_neg_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b99SVLwwBxL",
        "outputId": "fc589ad6-c5db-41ea-f204-d9444c6befad"
      },
      "source": [
        "sum(test_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0aAVv9KI-gG"
      },
      "source": [
        "# DGL code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf_ll3lj0goW"
      },
      "source": [
        "\"\"\"\r\n",
        "Graph Attention Networks in DGL using SPMV optimization.\r\n",
        "References\r\n",
        "----------\r\n",
        "Paper: https://arxiv.org/abs/1710.10903\r\n",
        "Author's code: https://github.com/PetarV-/GAT\r\n",
        "Pytorch implementation: https://github.com/Diego999/pyGAT\r\n",
        "\"\"\"\r\n",
        "def accuracy_ae(logits, labels):\r\n",
        "    # acc function\r\n",
        "    correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(logits), 0.5), tf.int32),\r\n",
        "                                  tf.cast(tf.sparse.to_dense(convert_sparse_matrix_to_sparse_tensor(labels)), tf.int32))\r\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n",
        "    return acc.numpy().item()\r\n",
        "\r\n",
        "def accuracy_cls(logits, labels):\r\n",
        "    indices = tf.math.argmax(logits, axis=1)\r\n",
        "    label_indices = tf.math.argmax(labels, axis=1)\r\n",
        "    acc = tf.reduce_mean(tf.cast(indices == label_indices, dtype=tf.float32))\r\n",
        "    return acc.numpy().item()\r\n",
        "\r\n",
        "\r\n",
        "def evaluate_ae(model, features, labels):\r\n",
        "    logits = model(features, training=False)\r\n",
        "    return accuracy_ae(logits, labels)\r\n",
        "\r\n",
        "def evaluate_cls(model, features, labels, mask):\r\n",
        "    logits = model(features, training=False)\r\n",
        "    logits = logits[mask]\r\n",
        "    labels = labels[mask]\r\n",
        "    return accuracy_cls(logits, labels)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMym_i7w0kfn"
      },
      "source": [
        "## GAT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Li_0zcCDqBO"
      },
      "source": [
        "class GAT(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 g,\n",
        "                 num_layers,\n",
        "                 in_dim,\n",
        "                 num_hidden,\n",
        "                 num_classes,\n",
        "                 heads,\n",
        "                 activation,\n",
        "                 feat_drop,\n",
        "                 attn_drop,\n",
        "                 negative_slope,\n",
        "                 residual):\n",
        "        super(GAT, self).__init__()\n",
        "        self.g = g\n",
        "        self.num_layers = num_layers\n",
        "        self.gat_layers = []\n",
        "        self.activation = activation\n",
        "        # input projection (no residual)\n",
        "        self.gat_layers.append(GATConv(\n",
        "            in_dim, num_hidden[0], heads[0],\n",
        "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
        "        # hidden layers\n",
        "        for l in range(1, num_layers):\n",
        "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
        "            self.gat_layers.append(GATConv(\n",
        "                num_hidden[l-1] * heads[l-1], num_hidden[l], heads[l],\n",
        "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
        "        # output projection\n",
        "        self.gat_layers.append(GATConv(\n",
        "            num_hidden[-1] * heads[-2], num_classes, heads[-1],\n",
        "            feat_drop, attn_drop, negative_slope, residual, None))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = inputs\n",
        "        for l in range(self.num_layers):\n",
        "            h = self.gat_layers[l](self.g, h)\n",
        "            h = tf.reshape(h, (h.shape[0], -1))\n",
        "        # output projection\n",
        "        logits = tf.reduce_mean(self.gat_layers[-1](self.g, h), axis=1)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSSP2lHY0qsF"
      },
      "source": [
        "## Simple GCN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd5nK8Is0nBm"
      },
      "source": [
        "class GCN(tf.keras.Model):\r\n",
        "    def __init__(self,\r\n",
        "                 g,\r\n",
        "                 in_feats,\r\n",
        "                 n_hidden,\r\n",
        "                 n_classes,\r\n",
        "                 n_layers,\r\n",
        "                 activation,\r\n",
        "                 dropout):\r\n",
        "        super(GCN, self).__init__()\r\n",
        "        self.g = g\r\n",
        "        self.layer_list = []\r\n",
        "        # input layer\r\n",
        "        self.layer_list.append(GraphConv(in_feats, n_hidden[0], activation=activation))\r\n",
        "        # hidden layers\r\n",
        "        for i in range(1, n_layers):\r\n",
        "            self.layer_list.append(GraphConv(n_hidden[i-1], n_hidden[i], activation=activation))\r\n",
        "        # output layer\r\n",
        "        self.layer_list.append(GraphConv(n_hidden[-1], n_classes))\r\n",
        "        self.dropout = layers.Dropout(dropout)\r\n",
        "\r\n",
        "    def call(self, features):\r\n",
        "        h = features\r\n",
        "        for i, layer in enumerate(self.layer_list):\r\n",
        "            if i != 0:\r\n",
        "                h = self.dropout(h)\r\n",
        "            h = layer(self.g, h)\r\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpjYPCS0unu"
      },
      "source": [
        "## process code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58wOefd4OjqB"
      },
      "source": [
        "g = cuda_humannet_dgl\n",
        "in_dim = input_features.shape[1]\n",
        "num_hiddens = [256, 128, 64]\n",
        "num_layers = len(num_hiddens)\n",
        "num_classes = 2\n",
        "heads = [8, 8, 8, 8]\n",
        "activation = tf.keras.activations.relu\n",
        "feat_drop = 0.1\n",
        "attn_drop = 0.1\n",
        "dropout = 0.1\n",
        "negative_slope = 0.2\n",
        "residual = True\n",
        "norm = 'both'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgt5ZSRhTbe"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "loss_fcn = tf.nn.softmax_cross_entropy_with_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLukByAUYZEp"
      },
      "source": [
        "train_input = tf.convert_to_tensor(input_features, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tBNABaMfrtY"
      },
      "source": [
        "def process(model, epochs, train_input, label_array, train_mask, val_mask, test_mask, fastmode):\r\n",
        "  weight_decay = 0.02\r\n",
        "\r\n",
        "  epochs_legend = [i+1 for i in range(epochs)]\r\n",
        "  loss_list = list()\r\n",
        "  train_acc_list = list()\r\n",
        "  val_acc_list = list()\r\n",
        "\r\n",
        "  for epoch in tqdm(range(epochs)):\r\n",
        "      # forward\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "          tape.watch(model.trainable_weights)\r\n",
        "          logits = model(train_input, training=True)\r\n",
        "\r\n",
        "          loss_value = tf.reduce_mean(loss_fcn(\r\n",
        "              labels=label_array[train_mask], logits=logits[train_mask]))\r\n",
        "          loss_list.append(loss_value.numpy().item())\r\n",
        "          # # Manually Weight Decay\r\n",
        "          # # We found Tensorflow has a different implementation on weight decay\r\n",
        "          # # of Adam(W) optimizer with PyTorch. And this results in worse results.\r\n",
        "          # # Manually adding weights to the loss to do weight decay solves this problem.\r\n",
        "          # for weight in model.trainable_weights:\r\n",
        "          #     loss_value = loss_value + \\\r\n",
        "          #         weight_decay*tf.nn.l2_loss(weight)\r\n",
        "\r\n",
        "          grads = tape.gradient(loss_value, model.trainable_weights)\r\n",
        "          optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n",
        "\r\n",
        "      train_acc = accuracy(logits[train_mask], label_array[train_mask])\r\n",
        "      train_acc_list.append(train_acc)\r\n",
        "\r\n",
        "      if fastmode:\r\n",
        "          val_acc = evaluate(model, train_input, label_array, val_mask)\r\n",
        "      else:\r\n",
        "          val_acc = evaluate(model, train_input, label_array, val_mask)\r\n",
        "          # if args.early_stop:\r\n",
        "          #     if stopper.step(val_acc, model):\r\n",
        "          #         break\r\n",
        "\r\n",
        "      val_acc_list.append(val_acc)\r\n",
        "\r\n",
        "      print(\"Epoch {:05d}| Loss {:.4f} | TrainAcc {:.4f} |\"\r\n",
        "            \" ValAcc {:.4f}\".\r\n",
        "            format(epoch, loss_value.numpy().item(), train_acc,\r\n",
        "                    val_acc))\r\n",
        "\r\n",
        "  print()\r\n",
        "  # if args.early_stop:\r\n",
        "  #     model.load_weights('es_checkpoint.pb')\r\n",
        "\r\n",
        "  acc = evaluate(model, train_input, label_array, test_mask)\r\n",
        "  print(\"Test Accuracy {:.4f}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHRkFO_KlXe2"
      },
      "source": [
        "model_gcn = GCN(g, in_dim, num_hiddens, num_classes, num_layers, activation, dropout)\r\n",
        "process(model_gcn, 100, train_input, label_array, train_mask, val_mask, test_mask, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xR6ggsqflWc"
      },
      "source": [
        "model_gat = GAT(g, num_layers, in_dim, num_hiddens, num_classes, heads, activation, feat_drop, attn_drop, negative_slope, residual)\n",
        "process(model_gat, 50, train_input, label_array, train_mask, val_mask, test_mask, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaJymXwIN9bo"
      },
      "source": [
        "def label_check(model, input_value, label_array, mask):\r\n",
        "  logits = model_gcn(input_value, training=False)\r\n",
        "  result = pd.DataFrame({'label': tf.math.argmax(label_array[mask], axis=1).numpy(), \r\n",
        "                         'pred': tf.math.argmax(logits[mask], axis=1).numpy()})\r\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeWZK9_LPIz9"
      },
      "source": [
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnIs3lOsOtCn"
      },
      "source": [
        "label_check(model_gat, train_input, label_array, test_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKpLmUGyGSKP"
      },
      "source": [
        "tf.math.argmax(label_array[train_mask], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2X1P8iNMp-J",
        "outputId": "8841ed2f-a58d-44e4-c433-4d3def66848b"
      },
      "source": [
        "logits = model_gcn(train_input, training=False)\r\n",
        "tf.math.argmax(logits[test_mask], axis=1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FKijjWkbqrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eadd394-f81b-4942-b599-b5961c34acf6"
      },
      "source": [
        "logits = model_gat(train_input, training=False)\r\n",
        "tf.math.argmax(logits[val_mask], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(86,), dtype=int64, numpy=\n",
              "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dPXEwVc_Hzc"
      },
      "source": [
        "label_array[test_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK7aGTahJzPP"
      },
      "source": [
        "label_indices = tf.math.argmax(label_array[test_mask], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnzNc7V8J1kb",
        "outputId": "ca8dab57-9062-48ce-934a-f21da2689380"
      },
      "source": [
        "label_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(202,), dtype=int64, numpy=\n",
              "array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3o27iIalWcC"
      },
      "source": [
        "label_indices = tf.math.argmax(test_value, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeLcBod6KAdh",
        "outputId": "d2b09165-3978-4c06-fdbf-ea3b11fe948f"
      },
      "source": [
        "label_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLgGkoZInR25",
        "outputId": "57cdb1b5-12ee-4923-a7c2-5057cdd3fe60"
      },
      "source": [
        "logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13195, 2), dtype=float32, numpy=\n",
              "array([[-5.812728 , 11.294597 ],\n",
              "       [-2.6245732,  3.8273547],\n",
              "       [ 4.1257386, -2.0075014],\n",
              "       ...,\n",
              "       [-3.9628217,  9.255359 ],\n",
              "       [-1.0786356,  8.510575 ],\n",
              "       [-0.2409327,  4.230225 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT_kafKSCmjs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "707b2b6c-fc37-4d92-b0e6-6ba3a9525a68"
      },
      "source": [
        "plt.plot(epochs_legend, loss_list)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1NmV10mI3aX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f95f9e73-ad6f-4049-a0c1-df3935b53beb"
      },
      "source": [
        "axes = plt.gca()\n",
        "axes.set_ylim([0,1])\n",
        "\n",
        "plt.plot(epochs_legend, train_acc_list, marker='', color='olive', linewidth=2, label=\"Train_ACC\")\n",
        "plt.plot(epochs_legend, val_acc_list, marker='', color='red', linewidth=2, label=\"Val_ACC\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f33153f9208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "SkYnUxAYePTE",
        "outputId": "56cbba9f-4121-4927-9ea6-acd2d47b9f84"
      },
      "source": [
        "axes = plt.gca()\r\n",
        "axes.set_ylim([0,1])\r\n",
        "\r\n",
        "plt.plot(epochs_legend, train_acc_list, marker='', color='olive', linewidth=2, label=\"Train_ACC\")\r\n",
        "plt.plot(epochs_legend, val_acc_list, marker='', color='red', linewidth=2, label=\"Val_ACC\")\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3552919eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE0CkJ3aJW3g"
      },
      "source": [
        "# GAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFofYcHQD-ym"
      },
      "source": [
        "def get_roc_score(model, train_input, adj_orig, edges_pos, edges_neg, emb=None):\r\n",
        "    def sigmoid(x):\r\n",
        "        return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "    # Predict on test set of edges\r\n",
        "    adj_rec = model(train_input, training=False).numpy()\r\n",
        "    preds = []\r\n",
        "    pos = []\r\n",
        "    for e in edges_pos:\r\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\r\n",
        "        pos.append(adj_orig[e[0], e[1]])\r\n",
        "\r\n",
        "\r\n",
        "    preds_neg = []\r\n",
        "    neg = []\r\n",
        "    for e in edges_neg:\r\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\r\n",
        "        neg.append(adj_orig[e[0], e[1]])\r\n",
        "\r\n",
        "    preds_all = np.hstack([preds, preds_neg])\r\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\r\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\r\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\r\n",
        "\r\n",
        "    return roc_score, ap_score"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SzeY9BWrU4h"
      },
      "source": [
        "g = cuda_humannet_dgl\r\n",
        "in_dim = input_features.shape[1]\r\n",
        "num_hiddens = [256, 128, 64]\r\n",
        "num_layers = len(num_hiddens)\r\n",
        "num_classes = 2\r\n",
        "heads = [8, 8, 8, 8]\r\n",
        "activation = tf.keras.activations.relu\r\n",
        "feat_drop = 0.1\r\n",
        "attn_drop = 0.1\r\n",
        "dropout = 0.1\r\n",
        "negative_slope = 0.2\r\n",
        "residual = True\r\n",
        "norm = 'both'"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5jf79jdrVUG"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "loss_fcn = tf.nn.weighted_cross_entropy_with_logits"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_55o8cwyrZI-"
      },
      "source": [
        "train_input = tf.convert_to_tensor(input_features, dtype=tf.float32)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx8pd3BLnKZ-"
      },
      "source": [
        "# Data split\r\n",
        "adj_train, train_edges, valid_pos, valid_neg, test_pos, test_neg = data_split(humannet_adj, 0.2, 0.1)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHd26CbhKb5g"
      },
      "source": [
        "class GraphAutoEncoder(tf.keras.Model):\r\n",
        "  \r\n",
        "    def __init__(self, adj_orig, dropout, original_dim, intermediate_dim, latent_dim, name=\"GCNModel\"):\r\n",
        "        super(GraphAutoEncoder, self).__init__(name=name)\r\n",
        "        self.dropout = dropout\r\n",
        "        self.pos_weight, self.norm = get_norm_terms(adj_orig)\r\n",
        "        self.adj_orig_tensor = tf.sparse.to_dense(convert_sparse_matrix_to_sparse_tensor(adj_orig))\r\n",
        "\r\n",
        "        # layers\r\n",
        "        self.graphconvolutionsparse = GraphConvolutionSparse(\r\n",
        "            input_dim=original_dim,\r\n",
        "            output_dim=intermediate_dim,\r\n",
        "            dropout=self.dropout)\r\n",
        "        self.graphconvolution = GraphConvolution(\r\n",
        "            input_dim=intermediate_dim,\r\n",
        "            output_dim=latent_dim,\r\n",
        "            dropout=self.dropout)\r\n",
        "        self.innerproductdecoder = InnerProductDecoder(\r\n",
        "            dropout=self.dropout\r\n",
        "        )\r\n",
        "\r\n",
        "    def set_adj(self, adj):\r\n",
        "        self.adj = adj\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        self.intermediate_latent = self.graphconvolutionsparse(self.adj, inputs)\r\n",
        "        self.final_latent = self.graphconvolution(self.adj, self.intermediate_latent)\r\n",
        "        self.reconstructed = self.innerproductdecoder(self.final_latent)\r\n",
        "\r\n",
        "        # loss function\r\n",
        "        loss = self.norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=tf.reshape(self.reconstructed, [-1]),\r\n",
        "                                                                          labels=tf.reshape(self.adj_orig_tensor, [-1]),\r\n",
        "                                                                          pos_weight=self.pos_weight))\r\n",
        "\r\n",
        "        self.add_loss(loss)\r\n",
        "\r\n",
        "        # acc function\r\n",
        "        correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(self.reconstructed), 0.5), tf.int32),\r\n",
        "                                      tf.cast(self.adj_orig_tensor, tf.int32))\r\n",
        "        acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n",
        "        self.add_metric(acc, name='acc', aggregation='mean')\r\n",
        "\r\n",
        "        return self.reconstructed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_I_GMmxJsxw"
      },
      "source": [
        "class GAE(tf.keras.Model):\r\n",
        "    def __init__(self,\r\n",
        "                 g,\r\n",
        "                 in_feats,\r\n",
        "                 n_hidden,\r\n",
        "                 n_layers,\r\n",
        "                 activation,\r\n",
        "                 dropout):\r\n",
        "        super(GAE, self).__init__()\r\n",
        "        self.g = g\r\n",
        "        self.layer_list = []\r\n",
        "        # input layer\r\n",
        "        self.layer_list.append(GraphConv(in_feats, n_hidden[0], activation=activation))\r\n",
        "        # hidden layers\r\n",
        "        for i in range(1, n_layers):\r\n",
        "            self.layer_list.append(GraphConv(n_hidden[i-1], n_hidden[i], activation=activation))\r\n",
        "        # output layer\r\n",
        "        self.dropout = layers.Dropout(dropout)\r\n",
        "\r\n",
        "    def call(self, features):\r\n",
        "        h = features\r\n",
        "        for i, layer in enumerate(self.layer_list):\r\n",
        "            if i != 0:\r\n",
        "                h = self.dropout(h)\r\n",
        "            h = layer(self.g, h)\r\n",
        "        h = self.dropout(h)\r\n",
        "        x = tf.transpose(h)\r\n",
        "        h = tf.matmul(h, x)\r\n",
        "        return h"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Um2Yf9WQJb"
      },
      "source": [
        "model_gae = GAE(g, in_dim, num_hiddens, num_layers, activation, dropout)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm5rt_54XiNq"
      },
      "source": [
        "logits = model_gae(train_input, training=False)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7905c8f329d14376ae1966da12376a0a",
            "cdd16987c28841b1a87cd71acbd0933b",
            "ad5d2a158d4a4a8da2d06b997d075519",
            "7f914190608b4ecaac17cc3f70624536",
            "5fb5c41ef22b43829f0eaa60757c9138",
            "233975c9b3e84365903f319f51244d84",
            "77ef1ccb27c14030b066c05667ad775a",
            "63714c4164f84c489b46e14a0da24bb1"
          ]
        },
        "id": "O50jUZk2gte_",
        "outputId": "160b73f2-bcdf-47da-a013-dbbefb06ea76"
      },
      "source": [
        "weight_decay = 0.02\r\n",
        "\r\n",
        "pos_weight = float(adj_train.shape[0] * adj_train.shape[0] - adj_train.sum()) / adj_train.sum()\r\n",
        "norm = adj_train.shape[0] * adj_train.shape[0] / float((adj_train.shape[0] * adj_train.shape[0] - adj_train.sum()) * 2)\r\n",
        "\r\n",
        "epochs_legend = [i+1 for i in range(500)]\r\n",
        "loss_list = list()\r\n",
        "train_acc_list = list()\r\n",
        "val_roc_list = list()\r\n",
        "val_ap_list = list()\r\n",
        "\r\n",
        "for epoch in tqdm(range(500)):\r\n",
        "    # forward\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        tape.watch(model_gae.trainable_weights)\r\n",
        "        logits = model_gae(train_input, training=True)\r\n",
        "\r\n",
        "        loss_value = norm * tf.reduce_mean(loss_fcn(\r\n",
        "            labels=tf.sparse.to_dense(convert_sparse_matrix_to_sparse_tensor(adj_train)), logits=logits, pos_weight=pos_weight))\r\n",
        "        loss_list.append(loss_value.numpy().item())\r\n",
        "        # Manually Weight Decay\r\n",
        "        # We found Tensorflow has a different implementation on weight decay\r\n",
        "        # of Adam(W) optimizer with PyTorch. And this results in worse results.\r\n",
        "        # Manually adding weights to the loss to do weight decay solves this problem.\r\n",
        "        for weight in model_gae.trainable_weights:\r\n",
        "            loss_value = loss_value + \\\r\n",
        "                weight_decay*tf.nn.l2_loss(weight)\r\n",
        "\r\n",
        "        grads = tape.gradient(loss_value, model_gae.trainable_weights)\r\n",
        "        optimizer.apply_gradients(zip(grads, model_gae.trainable_weights))\r\n",
        "\r\n",
        "    train_acc = accuracy_ae(logits, humannet_adj)\r\n",
        "    train_acc_list.append(train_acc)\r\n",
        "\r\n",
        "    roc_curr, ap_curr = get_roc_score(model_gae, train_input, humannet_adj, valid_pos, valid_neg)\r\n",
        "\r\n",
        "    val_roc_list.append(roc_curr)\r\n",
        "    val_ap_list.append(ap_curr)\r\n",
        "\r\n",
        "    print(\"Epoch {:05d}| Loss {:.4f} | TrainAcc {:.4f} |\"\r\n",
        "          \" ValAUROC {:.4f} | ValAP {:.4f}\".\r\n",
        "          format(epoch, loss_value.numpy().item(), train_acc,\r\n",
        "                  roc_curr, ap_curr))\r\n",
        "    \r\n",
        "\r\n",
        "print()\r\n",
        "# if args.early_stop:\r\n",
        "#     model.load_weights('es_checkpoint.pb')\r\n",
        "\r\n",
        "test_roc_curr, test_ap_curr = get_roc_score(model_gae, train_input, humannet_adj, test_pos, test_neg)\r\n",
        "print(\"Test AUROC {:.4f} | Test AP {:.4f}\".format(test_roc_curr, test_ap_curr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7905c8f329d14376ae1966da12376a0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZseK24_XtIi",
        "outputId": "9ea6ff2b-5593-44e0-e210-8bd067b377ae"
      },
      "source": [
        "logits.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([13195, 13195])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCVDq_W6HqZ5"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axoj62p1IVne",
        "outputId": "49031366-1b32-404e-e924-cf0abb2bc0d1"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDJIYYBHQvwt",
        "outputId": "3017b6dc-310f-4f58-fecf-acd5b0e60e8b"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOboycMtJs4a",
        "outputId": "d0434d60-1540-4459-d1b2-c46302f10c04"
      },
      "source": [
        "train_input[train_mask]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(929, 1234), dtype=float32, numpy=\n",
              "array([[1.19878609e-06, 0.00000000e+00, 3.37162169e-06, ...,\n",
              "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
              "       [6.97131400e-05, 7.73373176e-06, 3.57821264e-05, ...,\n",
              "        0.00000000e+00, 3.00000000e+00, 3.50000000e+00],\n",
              "       [1.23707669e-05, 7.71321629e-06, 1.22705615e-05, ...,\n",
              "        1.11111112e-01, 2.50000000e+00, 3.75000000e+00],\n",
              "       ...,\n",
              "       [1.29635708e-04, 1.55992457e-04, 1.01132857e-04, ...,\n",
              "        0.00000000e+00, 1.00000000e+00, 1.75000000e+00],\n",
              "       [2.63466558e-04, 2.65242474e-04, 7.40576710e-04, ...,\n",
              "        0.00000000e+00, 3.00000000e+00, 3.00000000e+00],\n",
              "       [1.80296856e-03, 4.37620271e-04, 1.24688784e-03, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.33333343e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YgJU-XLL_G3",
        "outputId": "445238dc-c848-44c7-e524-cb940267a1ed"
      },
      "source": [
        "label_array[train_mask].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(929, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "bRf0h1XbQ0bw",
        "outputId": "eccad63e-d4bd-4ce8-97bd-fc2c18ce4842"
      },
      "source": [
        "label_array[train_mask].reshape((929,2, ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-3fab7ddb81c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m929\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1858 into shape (929,2,0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b10bblw7REpm"
      },
      "source": [
        "def label_dimension_reduce(label_array):\r\n",
        "  result = list()\r\n",
        "  for label in label_array:\r\n",
        "    if label[0] == 1:\r\n",
        "      result.append(1)\r\n",
        "    else:\r\n",
        "      result.append(0)\r\n",
        "  return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q1F-v_9IXwn"
      },
      "source": [
        "feature_size = train_input.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEvoeqwfJDcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f0ce3c-ac4a-4b31-8d66-9220eb38fe2c"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.Input(shape=(feature_size, )),\r\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\r\n",
        "  tf.keras.layers.Dropout(0.2),\r\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "  tf.keras.layers.Dropout(0.2),\r\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "  tf.keras.layers.Dropout(0.2),\r\n",
        "  tf.keras.layers.Dense(2, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_input[train_mask], label_dimension_reduce(label_array[train_mask]), epochs=1000)\r\n",
        "\r\n",
        "model.evaluate(train_input[test_mask],  label_dimension_reduce(label_array[test_mask]), verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6472\n",
            "Epoch 2/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6647\n",
            "Epoch 3/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6433\n",
            "Epoch 4/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6874\n",
            "Epoch 5/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6490\n",
            "Epoch 6/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6795\n",
            "Epoch 7/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6756\n",
            "Epoch 8/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6762\n",
            "Epoch 9/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7097\n",
            "Epoch 10/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6589\n",
            "Epoch 11/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6791\n",
            "Epoch 12/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6992\n",
            "Epoch 13/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6922\n",
            "Epoch 14/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6876\n",
            "Epoch 15/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6971\n",
            "Epoch 16/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6779\n",
            "Epoch 17/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6828\n",
            "Epoch 18/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6893\n",
            "Epoch 19/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6774\n",
            "Epoch 20/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6861\n",
            "Epoch 21/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6916\n",
            "Epoch 22/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6960\n",
            "Epoch 23/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6831\n",
            "Epoch 24/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6520\n",
            "Epoch 25/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6989\n",
            "Epoch 26/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7060\n",
            "Epoch 27/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6772\n",
            "Epoch 28/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6970\n",
            "Epoch 29/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.6992\n",
            "Epoch 30/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.6884\n",
            "Epoch 31/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6870\n",
            "Epoch 32/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7060\n",
            "Epoch 33/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6998\n",
            "Epoch 34/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7157\n",
            "Epoch 35/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6858\n",
            "Epoch 36/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7051\n",
            "Epoch 37/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7048\n",
            "Epoch 38/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6821\n",
            "Epoch 39/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.6940\n",
            "Epoch 40/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7195\n",
            "Epoch 41/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7073\n",
            "Epoch 42/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6916\n",
            "Epoch 43/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7068\n",
            "Epoch 44/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.6987\n",
            "Epoch 45/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7345\n",
            "Epoch 46/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7268\n",
            "Epoch 47/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.6822\n",
            "Epoch 48/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7138\n",
            "Epoch 49/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7110\n",
            "Epoch 50/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6973\n",
            "Epoch 51/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7168\n",
            "Epoch 52/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7336\n",
            "Epoch 53/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7210\n",
            "Epoch 54/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7244\n",
            "Epoch 55/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7248\n",
            "Epoch 56/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7422\n",
            "Epoch 57/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7289\n",
            "Epoch 58/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6841\n",
            "Epoch 59/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7293\n",
            "Epoch 60/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7085\n",
            "Epoch 61/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7280\n",
            "Epoch 62/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7267\n",
            "Epoch 63/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.6981\n",
            "Epoch 64/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7099\n",
            "Epoch 65/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7247\n",
            "Epoch 66/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7065\n",
            "Epoch 67/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7271\n",
            "Epoch 68/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7482\n",
            "Epoch 69/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7161\n",
            "Epoch 70/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7414\n",
            "Epoch 71/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7305\n",
            "Epoch 72/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7169\n",
            "Epoch 73/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7188\n",
            "Epoch 74/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7240\n",
            "Epoch 75/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7540\n",
            "Epoch 76/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7176\n",
            "Epoch 77/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7426\n",
            "Epoch 78/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7187\n",
            "Epoch 79/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7326\n",
            "Epoch 80/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7154\n",
            "Epoch 81/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7265\n",
            "Epoch 82/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7431\n",
            "Epoch 83/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7394\n",
            "Epoch 84/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7265\n",
            "Epoch 85/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7464\n",
            "Epoch 86/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7649\n",
            "Epoch 87/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7511\n",
            "Epoch 88/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7469\n",
            "Epoch 89/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7463\n",
            "Epoch 90/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7222\n",
            "Epoch 91/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7401\n",
            "Epoch 92/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7219\n",
            "Epoch 93/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7658\n",
            "Epoch 94/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7197\n",
            "Epoch 95/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7484\n",
            "Epoch 96/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7482\n",
            "Epoch 97/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7392\n",
            "Epoch 98/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7123\n",
            "Epoch 99/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7613\n",
            "Epoch 100/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.6974\n",
            "Epoch 101/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7465\n",
            "Epoch 102/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7693\n",
            "Epoch 103/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7464\n",
            "Epoch 104/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7392\n",
            "Epoch 105/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7473\n",
            "Epoch 106/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7461\n",
            "Epoch 107/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7382\n",
            "Epoch 108/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7501\n",
            "Epoch 109/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7306\n",
            "Epoch 110/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7453\n",
            "Epoch 111/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7402\n",
            "Epoch 112/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7409\n",
            "Epoch 113/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7176\n",
            "Epoch 114/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7282\n",
            "Epoch 115/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7123\n",
            "Epoch 116/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7321\n",
            "Epoch 117/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7240\n",
            "Epoch 118/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7406\n",
            "Epoch 119/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7442\n",
            "Epoch 120/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7540\n",
            "Epoch 121/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7290\n",
            "Epoch 122/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7542\n",
            "Epoch 123/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7173\n",
            "Epoch 124/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7398\n",
            "Epoch 125/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7434\n",
            "Epoch 126/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7633\n",
            "Epoch 127/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7509\n",
            "Epoch 128/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7309\n",
            "Epoch 129/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7247\n",
            "Epoch 130/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7514\n",
            "Epoch 131/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7823\n",
            "Epoch 132/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7471\n",
            "Epoch 133/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7270\n",
            "Epoch 134/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7524\n",
            "Epoch 135/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6556\n",
            "Epoch 136/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7605\n",
            "Epoch 137/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7526\n",
            "Epoch 138/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7796\n",
            "Epoch 139/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7395\n",
            "Epoch 140/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7469\n",
            "Epoch 141/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7696\n",
            "Epoch 142/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7515\n",
            "Epoch 143/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7504\n",
            "Epoch 144/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7340\n",
            "Epoch 145/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7570\n",
            "Epoch 146/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7780\n",
            "Epoch 147/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7482\n",
            "Epoch 148/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7769\n",
            "Epoch 149/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7664\n",
            "Epoch 150/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7486\n",
            "Epoch 151/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7757\n",
            "Epoch 152/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7278\n",
            "Epoch 153/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7743\n",
            "Epoch 154/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7601\n",
            "Epoch 155/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7662\n",
            "Epoch 156/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7769\n",
            "Epoch 157/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8074\n",
            "Epoch 158/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7511\n",
            "Epoch 159/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7266\n",
            "Epoch 160/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7652\n",
            "Epoch 161/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7777\n",
            "Epoch 162/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7634\n",
            "Epoch 163/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7785\n",
            "Epoch 164/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7796\n",
            "Epoch 165/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7884\n",
            "Epoch 166/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7797\n",
            "Epoch 167/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7486\n",
            "Epoch 168/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7792\n",
            "Epoch 169/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7561\n",
            "Epoch 170/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7737\n",
            "Epoch 171/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7568\n",
            "Epoch 172/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7259\n",
            "Epoch 173/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7683\n",
            "Epoch 174/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7019\n",
            "Epoch 175/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7298\n",
            "Epoch 176/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7129\n",
            "Epoch 177/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7512\n",
            "Epoch 178/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7616\n",
            "Epoch 179/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7590\n",
            "Epoch 180/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7644\n",
            "Epoch 181/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7345\n",
            "Epoch 182/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7765\n",
            "Epoch 183/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7692\n",
            "Epoch 184/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7637\n",
            "Epoch 185/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7426\n",
            "Epoch 186/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7573\n",
            "Epoch 187/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7556\n",
            "Epoch 188/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7363\n",
            "Epoch 189/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7652\n",
            "Epoch 190/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7578\n",
            "Epoch 191/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7864\n",
            "Epoch 192/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7560\n",
            "Epoch 193/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7949\n",
            "Epoch 194/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7761\n",
            "Epoch 195/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7660\n",
            "Epoch 196/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7732\n",
            "Epoch 197/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7675\n",
            "Epoch 198/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7720\n",
            "Epoch 199/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7696\n",
            "Epoch 200/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7957\n",
            "Epoch 201/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7620\n",
            "Epoch 202/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7584\n",
            "Epoch 203/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7988\n",
            "Epoch 204/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7934\n",
            "Epoch 205/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7759\n",
            "Epoch 206/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7506\n",
            "Epoch 207/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7542\n",
            "Epoch 208/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7967\n",
            "Epoch 209/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7987\n",
            "Epoch 210/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.7975\n",
            "Epoch 211/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8024\n",
            "Epoch 212/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7815\n",
            "Epoch 213/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7001\n",
            "Epoch 214/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7570\n",
            "Epoch 215/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7462\n",
            "Epoch 216/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7695\n",
            "Epoch 217/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7733\n",
            "Epoch 218/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7652\n",
            "Epoch 219/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7709\n",
            "Epoch 220/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7798\n",
            "Epoch 221/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7557\n",
            "Epoch 222/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7507\n",
            "Epoch 223/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7709\n",
            "Epoch 224/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7596\n",
            "Epoch 225/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7644\n",
            "Epoch 226/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7403\n",
            "Epoch 227/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7735\n",
            "Epoch 228/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8119\n",
            "Epoch 229/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7803\n",
            "Epoch 230/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8068\n",
            "Epoch 231/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.7867\n",
            "Epoch 232/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7858\n",
            "Epoch 233/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8024\n",
            "Epoch 234/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7775\n",
            "Epoch 235/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7686\n",
            "Epoch 236/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7716\n",
            "Epoch 237/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7829\n",
            "Epoch 238/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7526\n",
            "Epoch 239/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8071\n",
            "Epoch 240/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7898\n",
            "Epoch 241/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.7940\n",
            "Epoch 242/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7784\n",
            "Epoch 243/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7857\n",
            "Epoch 244/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7799\n",
            "Epoch 245/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7809\n",
            "Epoch 246/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8080\n",
            "Epoch 247/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8195\n",
            "Epoch 248/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8000\n",
            "Epoch 249/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7880\n",
            "Epoch 250/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7707\n",
            "Epoch 251/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7587\n",
            "Epoch 252/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7886\n",
            "Epoch 253/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8155\n",
            "Epoch 254/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7805\n",
            "Epoch 255/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7999\n",
            "Epoch 256/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7965\n",
            "Epoch 257/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7833\n",
            "Epoch 258/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7905\n",
            "Epoch 259/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7850\n",
            "Epoch 260/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7752\n",
            "Epoch 261/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8011\n",
            "Epoch 262/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8066\n",
            "Epoch 263/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8003\n",
            "Epoch 264/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7691\n",
            "Epoch 265/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7569\n",
            "Epoch 266/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7903\n",
            "Epoch 267/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8142\n",
            "Epoch 268/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7667\n",
            "Epoch 269/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7859\n",
            "Epoch 270/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7931\n",
            "Epoch 271/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7747\n",
            "Epoch 272/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7908\n",
            "Epoch 273/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8084\n",
            "Epoch 274/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7772\n",
            "Epoch 275/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8285\n",
            "Epoch 276/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7726\n",
            "Epoch 277/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7877\n",
            "Epoch 278/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8195\n",
            "Epoch 279/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7861\n",
            "Epoch 280/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8115\n",
            "Epoch 281/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7590\n",
            "Epoch 282/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8040\n",
            "Epoch 283/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7951\n",
            "Epoch 284/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7833\n",
            "Epoch 285/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7660\n",
            "Epoch 286/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7949\n",
            "Epoch 287/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8015\n",
            "Epoch 288/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.7849\n",
            "Epoch 289/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7968\n",
            "Epoch 290/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8074\n",
            "Epoch 291/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8148\n",
            "Epoch 292/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8008\n",
            "Epoch 293/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7733\n",
            "Epoch 294/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7660\n",
            "Epoch 295/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7789\n",
            "Epoch 296/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8014\n",
            "Epoch 297/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8048\n",
            "Epoch 298/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7922\n",
            "Epoch 299/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8002\n",
            "Epoch 300/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7886\n",
            "Epoch 301/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8046\n",
            "Epoch 302/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7904\n",
            "Epoch 303/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7884\n",
            "Epoch 304/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8105\n",
            "Epoch 305/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7871\n",
            "Epoch 306/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7910\n",
            "Epoch 307/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7612\n",
            "Epoch 308/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8071\n",
            "Epoch 309/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8036\n",
            "Epoch 310/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8145\n",
            "Epoch 311/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8143\n",
            "Epoch 312/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8149\n",
            "Epoch 313/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8052\n",
            "Epoch 314/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7809\n",
            "Epoch 315/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7875\n",
            "Epoch 316/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8005\n",
            "Epoch 317/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8059\n",
            "Epoch 318/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7652\n",
            "Epoch 319/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.7822\n",
            "Epoch 320/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8235\n",
            "Epoch 321/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.7944\n",
            "Epoch 322/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8014\n",
            "Epoch 323/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8273\n",
            "Epoch 324/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8202\n",
            "Epoch 325/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7861\n",
            "Epoch 326/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8127\n",
            "Epoch 327/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7862\n",
            "Epoch 328/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8021\n",
            "Epoch 329/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7953\n",
            "Epoch 330/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8295\n",
            "Epoch 331/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7883\n",
            "Epoch 332/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8196\n",
            "Epoch 333/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.7821\n",
            "Epoch 334/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8062\n",
            "Epoch 335/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8161\n",
            "Epoch 336/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8189\n",
            "Epoch 337/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8095\n",
            "Epoch 338/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8326\n",
            "Epoch 339/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7956\n",
            "Epoch 340/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8035\n",
            "Epoch 341/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8176\n",
            "Epoch 342/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8273\n",
            "Epoch 343/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7987\n",
            "Epoch 344/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8436\n",
            "Epoch 345/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8286\n",
            "Epoch 346/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8126\n",
            "Epoch 347/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8222\n",
            "Epoch 348/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8238\n",
            "Epoch 349/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8144\n",
            "Epoch 350/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8301\n",
            "Epoch 351/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7996\n",
            "Epoch 352/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8051\n",
            "Epoch 353/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8344\n",
            "Epoch 354/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8191\n",
            "Epoch 355/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7842\n",
            "Epoch 356/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8528\n",
            "Epoch 357/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8503\n",
            "Epoch 358/1000\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8445\n",
            "Epoch 359/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8357\n",
            "Epoch 360/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8108\n",
            "Epoch 361/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8046\n",
            "Epoch 362/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8179\n",
            "Epoch 363/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8262\n",
            "Epoch 364/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8252\n",
            "Epoch 365/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.7935\n",
            "Epoch 366/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8141\n",
            "Epoch 367/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.7975\n",
            "Epoch 368/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8418\n",
            "Epoch 369/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8146\n",
            "Epoch 370/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8181\n",
            "Epoch 371/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8302\n",
            "Epoch 372/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8332\n",
            "Epoch 373/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8169\n",
            "Epoch 374/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8360\n",
            "Epoch 375/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8228\n",
            "Epoch 376/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7949\n",
            "Epoch 377/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8387\n",
            "Epoch 378/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8248\n",
            "Epoch 379/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8403\n",
            "Epoch 380/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8414\n",
            "Epoch 381/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8418\n",
            "Epoch 382/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8236\n",
            "Epoch 383/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8252\n",
            "Epoch 384/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8032\n",
            "Epoch 385/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8159\n",
            "Epoch 386/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8459\n",
            "Epoch 387/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8439\n",
            "Epoch 388/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8399\n",
            "Epoch 389/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8123\n",
            "Epoch 390/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8188\n",
            "Epoch 391/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8451\n",
            "Epoch 392/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8312\n",
            "Epoch 393/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8565\n",
            "Epoch 394/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8473\n",
            "Epoch 395/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8103\n",
            "Epoch 396/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8497\n",
            "Epoch 397/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8358\n",
            "Epoch 398/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8227\n",
            "Epoch 399/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8204\n",
            "Epoch 400/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8243\n",
            "Epoch 401/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8378\n",
            "Epoch 402/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8208\n",
            "Epoch 403/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8049\n",
            "Epoch 404/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8323\n",
            "Epoch 405/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8326\n",
            "Epoch 406/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8428\n",
            "Epoch 407/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8275\n",
            "Epoch 408/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8454\n",
            "Epoch 409/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8353\n",
            "Epoch 410/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8198\n",
            "Epoch 411/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8222\n",
            "Epoch 412/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8508\n",
            "Epoch 413/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8488\n",
            "Epoch 414/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8213\n",
            "Epoch 415/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8559\n",
            "Epoch 416/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8002\n",
            "Epoch 417/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8317\n",
            "Epoch 418/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8009\n",
            "Epoch 419/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8014\n",
            "Epoch 420/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8261\n",
            "Epoch 421/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8129\n",
            "Epoch 422/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8338\n",
            "Epoch 423/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8276\n",
            "Epoch 424/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8158\n",
            "Epoch 425/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8394\n",
            "Epoch 426/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8239\n",
            "Epoch 427/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8308\n",
            "Epoch 428/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8202\n",
            "Epoch 429/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8434\n",
            "Epoch 430/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8478\n",
            "Epoch 431/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8405\n",
            "Epoch 432/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8190\n",
            "Epoch 433/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8076\n",
            "Epoch 434/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8488\n",
            "Epoch 435/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8335\n",
            "Epoch 436/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8097\n",
            "Epoch 437/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8217\n",
            "Epoch 438/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8419\n",
            "Epoch 439/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8333\n",
            "Epoch 440/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8470\n",
            "Epoch 441/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8092\n",
            "Epoch 442/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8026\n",
            "Epoch 443/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8012\n",
            "Epoch 444/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7686\n",
            "Epoch 445/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8111\n",
            "Epoch 446/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.7975\n",
            "Epoch 447/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.7976\n",
            "Epoch 448/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8291\n",
            "Epoch 449/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8217\n",
            "Epoch 450/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8204\n",
            "Epoch 451/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8479\n",
            "Epoch 452/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8129\n",
            "Epoch 453/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8128\n",
            "Epoch 454/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8396\n",
            "Epoch 455/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8154\n",
            "Epoch 456/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8317\n",
            "Epoch 457/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8147\n",
            "Epoch 458/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8359\n",
            "Epoch 459/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8294\n",
            "Epoch 460/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8299\n",
            "Epoch 461/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8274\n",
            "Epoch 462/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7863\n",
            "Epoch 463/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7743\n",
            "Epoch 464/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8136\n",
            "Epoch 465/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7867\n",
            "Epoch 466/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8118\n",
            "Epoch 467/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8225\n",
            "Epoch 468/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8164\n",
            "Epoch 469/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8117\n",
            "Epoch 470/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8234\n",
            "Epoch 471/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8288\n",
            "Epoch 472/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8241\n",
            "Epoch 473/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.7990\n",
            "Epoch 474/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8337\n",
            "Epoch 475/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8324\n",
            "Epoch 476/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.8047\n",
            "Epoch 477/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8030\n",
            "Epoch 478/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8241\n",
            "Epoch 479/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8109\n",
            "Epoch 480/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8074\n",
            "Epoch 481/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8224\n",
            "Epoch 482/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8361\n",
            "Epoch 483/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8115\n",
            "Epoch 484/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8065\n",
            "Epoch 485/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8122\n",
            "Epoch 486/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8427\n",
            "Epoch 487/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8202\n",
            "Epoch 488/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8354\n",
            "Epoch 489/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8425\n",
            "Epoch 490/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8215\n",
            "Epoch 491/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8307\n",
            "Epoch 492/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8346\n",
            "Epoch 493/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7977\n",
            "Epoch 494/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8368\n",
            "Epoch 495/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8238\n",
            "Epoch 496/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8502\n",
            "Epoch 497/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8103\n",
            "Epoch 498/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8284\n",
            "Epoch 499/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8332\n",
            "Epoch 500/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8610\n",
            "Epoch 501/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8412\n",
            "Epoch 502/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8440\n",
            "Epoch 503/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8281\n",
            "Epoch 504/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7922\n",
            "Epoch 505/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8257\n",
            "Epoch 506/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8250\n",
            "Epoch 507/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.7992\n",
            "Epoch 508/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8259\n",
            "Epoch 509/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8205\n",
            "Epoch 510/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8401\n",
            "Epoch 511/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8072\n",
            "Epoch 512/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8157\n",
            "Epoch 513/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8435\n",
            "Epoch 514/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8176\n",
            "Epoch 515/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8550\n",
            "Epoch 516/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8291\n",
            "Epoch 517/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8328\n",
            "Epoch 518/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8379\n",
            "Epoch 519/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7868\n",
            "Epoch 520/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8480\n",
            "Epoch 521/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8261\n",
            "Epoch 522/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8671\n",
            "Epoch 523/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8200\n",
            "Epoch 524/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8620\n",
            "Epoch 525/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8253\n",
            "Epoch 526/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7900\n",
            "Epoch 527/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7614\n",
            "Epoch 528/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.7999\n",
            "Epoch 529/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8196\n",
            "Epoch 530/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8142\n",
            "Epoch 531/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8199\n",
            "Epoch 532/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8206\n",
            "Epoch 533/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8253\n",
            "Epoch 534/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7810\n",
            "Epoch 535/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7899\n",
            "Epoch 536/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8206\n",
            "Epoch 537/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8370\n",
            "Epoch 538/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7888\n",
            "Epoch 539/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8085\n",
            "Epoch 540/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8344\n",
            "Epoch 541/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8216\n",
            "Epoch 542/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8402\n",
            "Epoch 543/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8192\n",
            "Epoch 544/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8486\n",
            "Epoch 545/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8182\n",
            "Epoch 546/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8545\n",
            "Epoch 547/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8564\n",
            "Epoch 548/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8231\n",
            "Epoch 549/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.8079\n",
            "Epoch 550/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8067\n",
            "Epoch 551/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8319\n",
            "Epoch 552/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8321\n",
            "Epoch 553/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8398\n",
            "Epoch 554/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8503\n",
            "Epoch 555/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8599\n",
            "Epoch 556/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8555\n",
            "Epoch 557/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8648\n",
            "Epoch 558/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8380\n",
            "Epoch 559/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8291\n",
            "Epoch 560/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8418\n",
            "Epoch 561/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8482\n",
            "Epoch 562/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7902\n",
            "Epoch 563/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.7824\n",
            "Epoch 564/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8132\n",
            "Epoch 565/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8348\n",
            "Epoch 566/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8288\n",
            "Epoch 567/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8371\n",
            "Epoch 568/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8441\n",
            "Epoch 569/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8390\n",
            "Epoch 570/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8375\n",
            "Epoch 571/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8436\n",
            "Epoch 572/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8629\n",
            "Epoch 573/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8558\n",
            "Epoch 574/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8238\n",
            "Epoch 575/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8424\n",
            "Epoch 576/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8294\n",
            "Epoch 577/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8540\n",
            "Epoch 578/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8566\n",
            "Epoch 579/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8232\n",
            "Epoch 580/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8528\n",
            "Epoch 581/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8306\n",
            "Epoch 582/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8798\n",
            "Epoch 583/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8419\n",
            "Epoch 584/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.8558\n",
            "Epoch 585/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8287\n",
            "Epoch 586/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8140\n",
            "Epoch 587/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8041\n",
            "Epoch 588/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8346\n",
            "Epoch 589/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8284\n",
            "Epoch 590/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8263\n",
            "Epoch 591/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8449\n",
            "Epoch 592/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8295\n",
            "Epoch 593/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8578\n",
            "Epoch 594/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8290\n",
            "Epoch 595/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8036\n",
            "Epoch 596/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8163\n",
            "Epoch 597/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7808\n",
            "Epoch 598/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7894\n",
            "Epoch 599/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8049\n",
            "Epoch 600/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7941\n",
            "Epoch 601/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8134\n",
            "Epoch 602/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8214\n",
            "Epoch 603/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.7991\n",
            "Epoch 604/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8275\n",
            "Epoch 605/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.7991\n",
            "Epoch 606/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8385\n",
            "Epoch 607/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8106\n",
            "Epoch 608/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8313\n",
            "Epoch 609/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8246\n",
            "Epoch 610/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8422\n",
            "Epoch 611/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8547\n",
            "Epoch 612/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8146\n",
            "Epoch 613/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.7953\n",
            "Epoch 614/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8338\n",
            "Epoch 615/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8464\n",
            "Epoch 616/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8194\n",
            "Epoch 617/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8388\n",
            "Epoch 618/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8432\n",
            "Epoch 619/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8088\n",
            "Epoch 620/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7908\n",
            "Epoch 621/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7892\n",
            "Epoch 622/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8302\n",
            "Epoch 623/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8027\n",
            "Epoch 624/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8167\n",
            "Epoch 625/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8227\n",
            "Epoch 626/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8212\n",
            "Epoch 627/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8438\n",
            "Epoch 628/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8250\n",
            "Epoch 629/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8227\n",
            "Epoch 630/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8211\n",
            "Epoch 631/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8524\n",
            "Epoch 632/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7533\n",
            "Epoch 633/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8420\n",
            "Epoch 634/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8231\n",
            "Epoch 635/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8606\n",
            "Epoch 636/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8697\n",
            "Epoch 637/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8052\n",
            "Epoch 638/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8490\n",
            "Epoch 639/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8302\n",
            "Epoch 640/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8403\n",
            "Epoch 641/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8188\n",
            "Epoch 642/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8347\n",
            "Epoch 643/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8614\n",
            "Epoch 644/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8624\n",
            "Epoch 645/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8588\n",
            "Epoch 646/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8434\n",
            "Epoch 647/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8270\n",
            "Epoch 648/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8535\n",
            "Epoch 649/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8619\n",
            "Epoch 650/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8494\n",
            "Epoch 651/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8493\n",
            "Epoch 652/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8304\n",
            "Epoch 653/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8458\n",
            "Epoch 654/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8384\n",
            "Epoch 655/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8473\n",
            "Epoch 656/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8507\n",
            "Epoch 657/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8207\n",
            "Epoch 658/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8000\n",
            "Epoch 659/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8496\n",
            "Epoch 660/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8556\n",
            "Epoch 661/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8557\n",
            "Epoch 662/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8565\n",
            "Epoch 663/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8487\n",
            "Epoch 664/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8605\n",
            "Epoch 665/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8526\n",
            "Epoch 666/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8509\n",
            "Epoch 667/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8687\n",
            "Epoch 668/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8583\n",
            "Epoch 669/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8239\n",
            "Epoch 670/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8690\n",
            "Epoch 671/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8365\n",
            "Epoch 672/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8487\n",
            "Epoch 673/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8200\n",
            "Epoch 674/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8300\n",
            "Epoch 675/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8284\n",
            "Epoch 676/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8416\n",
            "Epoch 677/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7720\n",
            "Epoch 678/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8435\n",
            "Epoch 679/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8409\n",
            "Epoch 680/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8166\n",
            "Epoch 681/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8436\n",
            "Epoch 682/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8540\n",
            "Epoch 683/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8304\n",
            "Epoch 684/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.7870\n",
            "Epoch 685/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8153\n",
            "Epoch 686/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8131\n",
            "Epoch 687/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8445\n",
            "Epoch 688/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7310\n",
            "Epoch 689/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7800\n",
            "Epoch 690/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.7964\n",
            "Epoch 691/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8102\n",
            "Epoch 692/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7876\n",
            "Epoch 693/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8376\n",
            "Epoch 694/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8452\n",
            "Epoch 695/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8289\n",
            "Epoch 696/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8290\n",
            "Epoch 697/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8011\n",
            "Epoch 698/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8085\n",
            "Epoch 699/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8328\n",
            "Epoch 700/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7945\n",
            "Epoch 701/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8492\n",
            "Epoch 702/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8379\n",
            "Epoch 703/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8546\n",
            "Epoch 704/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8023\n",
            "Epoch 705/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7787\n",
            "Epoch 706/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8470\n",
            "Epoch 707/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8550\n",
            "Epoch 708/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7697\n",
            "Epoch 709/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8440\n",
            "Epoch 710/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8333\n",
            "Epoch 711/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8467\n",
            "Epoch 712/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8413\n",
            "Epoch 713/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8152\n",
            "Epoch 714/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8349\n",
            "Epoch 715/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8377\n",
            "Epoch 716/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8490\n",
            "Epoch 717/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8729\n",
            "Epoch 718/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8665\n",
            "Epoch 719/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8104\n",
            "Epoch 720/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8195\n",
            "Epoch 721/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8286\n",
            "Epoch 722/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8325\n",
            "Epoch 723/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8356\n",
            "Epoch 724/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8126\n",
            "Epoch 725/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7807\n",
            "Epoch 726/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8167\n",
            "Epoch 727/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8421\n",
            "Epoch 728/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8418\n",
            "Epoch 729/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8482\n",
            "Epoch 730/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8485\n",
            "Epoch 731/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8581\n",
            "Epoch 732/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8466\n",
            "Epoch 733/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8307\n",
            "Epoch 734/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8630\n",
            "Epoch 735/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8387\n",
            "Epoch 736/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8316\n",
            "Epoch 737/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7967\n",
            "Epoch 738/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8182\n",
            "Epoch 739/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8397\n",
            "Epoch 740/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8747\n",
            "Epoch 741/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8459\n",
            "Epoch 742/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8266\n",
            "Epoch 743/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8408\n",
            "Epoch 744/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8644\n",
            "Epoch 745/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8527\n",
            "Epoch 746/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8299\n",
            "Epoch 747/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8606\n",
            "Epoch 748/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8447\n",
            "Epoch 749/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8409\n",
            "Epoch 750/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8487\n",
            "Epoch 751/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8562\n",
            "Epoch 752/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8496\n",
            "Epoch 753/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8451\n",
            "Epoch 754/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8626\n",
            "Epoch 755/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8492\n",
            "Epoch 756/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8546\n",
            "Epoch 757/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8586\n",
            "Epoch 758/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8345\n",
            "Epoch 759/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8542\n",
            "Epoch 760/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8381\n",
            "Epoch 761/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8449\n",
            "Epoch 762/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8246\n",
            "Epoch 763/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8518\n",
            "Epoch 764/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8304\n",
            "Epoch 765/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8601\n",
            "Epoch 766/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8133\n",
            "Epoch 767/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8442\n",
            "Epoch 768/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8390\n",
            "Epoch 769/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8395\n",
            "Epoch 770/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8402\n",
            "Epoch 771/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8420\n",
            "Epoch 772/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8572\n",
            "Epoch 773/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8471\n",
            "Epoch 774/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8713\n",
            "Epoch 775/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8392\n",
            "Epoch 776/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8749\n",
            "Epoch 777/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8562\n",
            "Epoch 778/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8777\n",
            "Epoch 779/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8129\n",
            "Epoch 780/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8559\n",
            "Epoch 781/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8331\n",
            "Epoch 782/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8366\n",
            "Epoch 783/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8399\n",
            "Epoch 784/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8385\n",
            "Epoch 785/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8335\n",
            "Epoch 786/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8294\n",
            "Epoch 787/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8357\n",
            "Epoch 788/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8544\n",
            "Epoch 789/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8345\n",
            "Epoch 790/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8040\n",
            "Epoch 791/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8524\n",
            "Epoch 792/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8214\n",
            "Epoch 793/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8359\n",
            "Epoch 794/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8343\n",
            "Epoch 795/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8363\n",
            "Epoch 796/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8275\n",
            "Epoch 797/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8388\n",
            "Epoch 798/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8196\n",
            "Epoch 799/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8368\n",
            "Epoch 800/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.8706\n",
            "Epoch 801/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8406\n",
            "Epoch 802/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8258\n",
            "Epoch 803/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8634\n",
            "Epoch 804/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.8540\n",
            "Epoch 805/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8409\n",
            "Epoch 806/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8734\n",
            "Epoch 807/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8030\n",
            "Epoch 808/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8320\n",
            "Epoch 809/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8676\n",
            "Epoch 810/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8693\n",
            "Epoch 811/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8314\n",
            "Epoch 812/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8439\n",
            "Epoch 813/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8332\n",
            "Epoch 814/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8466\n",
            "Epoch 815/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8508\n",
            "Epoch 816/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8550\n",
            "Epoch 817/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8325\n",
            "Epoch 818/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8650\n",
            "Epoch 819/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8338\n",
            "Epoch 820/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8560\n",
            "Epoch 821/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8270\n",
            "Epoch 822/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8297\n",
            "Epoch 823/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8553\n",
            "Epoch 824/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8087\n",
            "Epoch 825/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.7963\n",
            "Epoch 826/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8322\n",
            "Epoch 827/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8556\n",
            "Epoch 828/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8301\n",
            "Epoch 829/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8523\n",
            "Epoch 830/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8624\n",
            "Epoch 831/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8418\n",
            "Epoch 832/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8662\n",
            "Epoch 833/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8163\n",
            "Epoch 834/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8421\n",
            "Epoch 835/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.7811\n",
            "Epoch 836/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8352\n",
            "Epoch 837/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8269\n",
            "Epoch 838/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8577\n",
            "Epoch 839/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8630\n",
            "Epoch 840/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8605\n",
            "Epoch 841/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8653\n",
            "Epoch 842/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8555\n",
            "Epoch 843/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8899\n",
            "Epoch 844/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8567\n",
            "Epoch 845/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8558\n",
            "Epoch 846/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8653\n",
            "Epoch 847/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8495\n",
            "Epoch 848/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8513\n",
            "Epoch 849/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8565\n",
            "Epoch 850/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8576\n",
            "Epoch 851/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8665\n",
            "Epoch 852/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8662\n",
            "Epoch 853/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8411\n",
            "Epoch 854/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8623\n",
            "Epoch 855/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8462\n",
            "Epoch 856/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7950\n",
            "Epoch 857/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8126\n",
            "Epoch 858/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8422\n",
            "Epoch 859/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8592\n",
            "Epoch 860/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8552\n",
            "Epoch 861/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8366\n",
            "Epoch 862/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8476\n",
            "Epoch 863/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8433\n",
            "Epoch 864/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8564\n",
            "Epoch 865/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8862\n",
            "Epoch 866/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8501\n",
            "Epoch 867/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8541\n",
            "Epoch 868/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8446\n",
            "Epoch 869/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8445\n",
            "Epoch 870/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8560\n",
            "Epoch 871/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8467\n",
            "Epoch 872/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8492\n",
            "Epoch 873/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8380\n",
            "Epoch 874/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8699\n",
            "Epoch 875/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8689\n",
            "Epoch 876/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8168\n",
            "Epoch 877/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8867\n",
            "Epoch 878/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8291\n",
            "Epoch 879/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8579\n",
            "Epoch 880/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8682\n",
            "Epoch 881/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8467\n",
            "Epoch 882/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8433\n",
            "Epoch 883/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8315\n",
            "Epoch 884/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.8652\n",
            "Epoch 885/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8445\n",
            "Epoch 886/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8372\n",
            "Epoch 887/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8398\n",
            "Epoch 888/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8882\n",
            "Epoch 889/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8566\n",
            "Epoch 890/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8754\n",
            "Epoch 891/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8420\n",
            "Epoch 892/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8451\n",
            "Epoch 893/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8077\n",
            "Epoch 894/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8072\n",
            "Epoch 895/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8138\n",
            "Epoch 896/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8419\n",
            "Epoch 897/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8360\n",
            "Epoch 898/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8363\n",
            "Epoch 899/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8413\n",
            "Epoch 900/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8314\n",
            "Epoch 901/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8480\n",
            "Epoch 902/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8504\n",
            "Epoch 903/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8471\n",
            "Epoch 904/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8709\n",
            "Epoch 905/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8621\n",
            "Epoch 906/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8246\n",
            "Epoch 907/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8121\n",
            "Epoch 908/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8204\n",
            "Epoch 909/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8356\n",
            "Epoch 910/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8350\n",
            "Epoch 911/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8156\n",
            "Epoch 912/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8355\n",
            "Epoch 913/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8573\n",
            "Epoch 914/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8406\n",
            "Epoch 915/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8568\n",
            "Epoch 916/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8356\n",
            "Epoch 917/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.7946\n",
            "Epoch 918/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8450\n",
            "Epoch 919/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8380\n",
            "Epoch 920/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8405\n",
            "Epoch 921/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8430\n",
            "Epoch 922/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8626\n",
            "Epoch 923/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8580\n",
            "Epoch 924/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8376\n",
            "Epoch 925/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8275\n",
            "Epoch 926/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8569\n",
            "Epoch 927/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8387\n",
            "Epoch 928/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8090\n",
            "Epoch 929/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8573\n",
            "Epoch 930/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8571\n",
            "Epoch 931/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8692\n",
            "Epoch 932/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7846\n",
            "Epoch 933/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.7753\n",
            "Epoch 934/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8290\n",
            "Epoch 935/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8237\n",
            "Epoch 936/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8281\n",
            "Epoch 937/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8281\n",
            "Epoch 938/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8340\n",
            "Epoch 939/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8430\n",
            "Epoch 940/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8248\n",
            "Epoch 941/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8496\n",
            "Epoch 942/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8413\n",
            "Epoch 943/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8463\n",
            "Epoch 944/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8511\n",
            "Epoch 945/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8623\n",
            "Epoch 946/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8655\n",
            "Epoch 947/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8218\n",
            "Epoch 948/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8385\n",
            "Epoch 949/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8218\n",
            "Epoch 950/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8518\n",
            "Epoch 951/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8429\n",
            "Epoch 952/1000\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8540\n",
            "Epoch 953/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8429\n",
            "Epoch 954/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8597\n",
            "Epoch 955/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8447\n",
            "Epoch 956/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8689\n",
            "Epoch 957/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8554\n",
            "Epoch 958/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8501\n",
            "Epoch 959/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8718\n",
            "Epoch 960/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8419\n",
            "Epoch 961/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8927\n",
            "Epoch 962/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8376\n",
            "Epoch 963/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8357\n",
            "Epoch 964/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8255\n",
            "Epoch 965/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8244\n",
            "Epoch 966/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8131\n",
            "Epoch 967/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8298\n",
            "Epoch 968/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8109\n",
            "Epoch 969/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8032\n",
            "Epoch 970/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8313\n",
            "Epoch 971/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8521\n",
            "Epoch 972/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8480\n",
            "Epoch 973/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8440\n",
            "Epoch 974/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8394\n",
            "Epoch 975/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8361\n",
            "Epoch 976/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8571\n",
            "Epoch 977/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8528\n",
            "Epoch 978/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8579\n",
            "Epoch 979/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8499\n",
            "Epoch 980/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8752\n",
            "Epoch 981/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8687\n",
            "Epoch 982/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9012\n",
            "Epoch 983/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8382\n",
            "Epoch 984/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8503\n",
            "Epoch 985/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8506\n",
            "Epoch 986/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.8527\n",
            "Epoch 987/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8577\n",
            "Epoch 988/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8608\n",
            "Epoch 989/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8609\n",
            "Epoch 990/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8388\n",
            "Epoch 991/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8744\n",
            "Epoch 992/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8383\n",
            "Epoch 993/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8510\n",
            "Epoch 994/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8417\n",
            "Epoch 995/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8562\n",
            "Epoch 996/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8401\n",
            "Epoch 997/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8730\n",
            "Epoch 998/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8658\n",
            "Epoch 999/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8526\n",
            "Epoch 1000/1000\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8481\n",
            "7/7 - 0s - loss: 1.7735 - accuracy: 0.5990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7734887599945068, 0.5990098714828491]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    }
  ]
}